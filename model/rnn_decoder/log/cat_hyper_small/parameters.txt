    batch_size = 64
    num_iteration = 6000
    save_every = 10
    verbose = 30
    max_len = 100
    params = tf.contrib.training.HParams(
        batch_size=batch_size,
        max_len=max_len,
        one_input_shape=5,
        lr=0.001,
        opt_name="Adam",
        classifier=False,
        bidir=False,
        model="./model/rnn_decoder/{}_hyper_small/{}".format(category, category),
        best_model="./model/rnn_decoder/{}_hyper_small/{}_best".format(category, category),
        summary="./model/rnn_decoder/log/{}_hyper_small".format(category),
        rnn_node="hyper_lstm",
        num_r_m=256,
        num_r_h=64,
        dim_z=16,
        d_type=tf.float64,
        # num_r_n=2048,
        gmm_dim=20,
        num_r_l=1,
        activation=tf.nn.tanh,
        dr_rnn=0.1,
        num_classes=8,
        clip_gradients=1.,
        mode=tf.estimator.ModeKeys.TRAIN,
        temper=1.,
        w_KL=1.,
        eta_min=0.01,
        R=0.99999,
        kl_min=0.20,
        train_with_inputs=True,
        restore=False,
        trained_steps=0
    )
